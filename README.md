# Pruning for Large Language Models


I am currently focusing on pruning large language models, including


- üìÑ **Papers**
  - [Survey](#survey)
  - [Weight-level Pruning](#Weight-level Pruning)
  - [Structured Pruning](#structured-pruning)
  - [Semi-structured Pruning](#semi-structured-pruning)
  
 
- üõ†Ô∏è **Application**
  
 
  
<strong> Last Update: 2025/12/16 </strong>





<a name="Surveys" />

## Papers
### Surveys
- [2024.11] Large Language Models in Operations Research: Methods, Applications, and Challenges, TACL [[Paper](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00704/125482)]
- [2024.01] Model Compression and Efficient Inference for Large Language Models: A Survey, arXiv [[Paper](https://openreview.net/forum?id=rNoHBvNzHn)]

### Weight-level Pruning
- [2025.11] FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement Learning, arXiv [[Paper](https://arxiv.org/abs/2511.18977)]
- [2023.07] SparseGPT: Massive Language Models Can be Accurately Pruned in One-shot, ICML [[Paper](https://dl.acm.org/doi/abs/10.5555/3618408.3618822)][[Code](https://github.com/IST-DASLab/sparsegpt)]
### Structured Pruning
- [2025.11] EvoP: Robust LLM Inference via Evolutionary Pruning, NLPCC [[Paper](https://link.springer.com/chapter/10.1007/978-981-95-3343-5_36)][[Code](https://github.com/luffy06/EvoP)]
- [2025.05] Let LLM Tell What to Prune and How Much to Prune, ICML [[Paper](https://openreview.net/forum?id=zFR5aWGaUs)][[Code](https://github.com/yangmzevery/PruneLLM)]
- [2025.05] SlimLLM: Accurate Structured Pruning for Large Language Models, ICML [[Paper](https://openreview.net/forum?id=2xjUkU7FDb)]
- [2025.04] Toward Adaptive Large Language Models Structured Pruning via Hybrid-grained Weight Importance Assessment, AAAI [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/34078)]
- [2025.04] KVPruner: Structural Pruning for Faster and Memory-Efficient Large Language Models, ICASSP [[Paper](https://ieeexplore.ieee.org/abstract/document/10889000)]
- [2025.02] MaskPrune: Mask-based LLM Pruning for Layer-wise Uniform Structures, arXiv [[Paper](https://arxiv.org/abs/2502.14008)]
- [2025.02] Adapt-Pruner: Adaptive Structural Pruning for Efficient Small Language Model Training, arXiv [[Paper](https://arxiv.org/abs/2502.03460)]
- [2025.01] CFSP: An Efficient Structured Pruning Framework for LLMs with Coarse-to-Fine Activation InformationÔºå COLING[[Paper](https://openreview.net/forum?id=OHkBBatwp3)][[Code](https://github.com/wyxscir/CFSP)]
- [2025.01] FASP: Fast and Accurate Structured Pruning of Large Language Models, arXiv [[Paper](https://arxiv.org/abs/2501.09412)]
- [2025.01] 2SSP: A Two-Stage Framework for Structured Pruning of LLMs, arXiv [[Paper](https://arxiv.org/abs/2501.17771)][[Code](https://github.com/FabrizioSandri/2SSP)]
- [2024.12] Adaptive Pruning for Large Language Models with Structural Importance Awareness, arXiv [[Paper](https://arxiv.org/abs/2412.15127)]
- [2024.12] SlimGPT: Layer-wise Structured Pruning for Large Language Models, NIPS [[Paper](https://dl.acm.org/doi/abs/10.5555/3737916.3741317)]
- [2024.12] LLM-BIP: Structured Pruning for Large Language Models with Block-Wise Forward Importance Propagation, arXiv [[Paper](https://arxiv.org/abs/2412.06419)]
- [2024.12] All-in-One Tuning and Structural Pruning for Domain-Specific LLMs, arXiv [[Paper](https://arxiv.org/abs/2412.14426)]
- [2024.10] DISP-LLM: Dimension-Independent Structural Pruning for Large Language Models, NIPS [[Paper](https://dl.acm.org/doi/abs/10.5555/3737916.3740221)]
- [2024.07] MINI-LLM: Memory-Efficient Structured Pruning for Large Language Models, arXiv [[Paper](https://arxiv.org/abs/2407.11681)]
- [2024.07] Prompt-prompted Adaptive Structured Pruning for Efficient LLM Generation, COLM [[Paper](https://openreview.net/pdf?id=4aqq9xTtih)][[Code](https://github.com/hdong920/GRIFFIN)]
- [2024.03] Fluctuation-Based Adaptive Structured Pruning for Large Language Models, AAAI [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/28960)][[Code](https://github.com/CASIA-IVA-Lab/FLAP)]
- [2024.02] Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes, arXiv [[Paper](https://arxiv.org/abs/2402.05406)]
- [2024.01] Structured Optimal Brain Pruning for Large Language Models, EMNLP [[Paper](https://openreview.net/forum?id=a8ruEUhpOv)]
- [2024.01] LoRAPrune: Structured Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning, ACL [[Paper](https://aclanthology.org/2024.findings-acl.178/)][[Code](https://github.com/aim-uofa/LoRAPrune)]
- [2024.01] Pruning as a Domain-specific LLM Extractor, NAACL [[Paper](https://pure.psu.edu/en/publications/pruning-as-a-domain-specific-llm-extractor/)][[Code](https://github.com/psunlpgroup/D-Pruner)]
### Semi-structured Pruning
- [2025.04] Pruning Large Language Models with Semi-Structural Adaptive Sparse Training, AAAI[[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/34592)]
- [2025.02] Progressive Binarization with Semi-Structured Pruning for LLMs, arXiv [[Paper](https://arxiv.org/abs/2502.01705)][[Code](https://github.com/XIANGLONGYAN/PBS2P)]
- 
